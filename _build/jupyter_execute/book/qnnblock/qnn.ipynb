{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29316b15",
   "metadata": {},
   "source": [
    "(qnn)=\n",
    "\n",
    "# Квантовые нейронные сети\n",
    "\n",
    "## Описание лекции\n",
    "\n",
    "В этой лекции мы пройдёмся по расширению идеи нейронных сетей на квантовые компьютеры  -- мы уже прошли и вариационные квантовые схемы (**VQC**), и комбинацию квантовых и классических градиентов в них в соответствующем блоке. Всё что осталось -- это объединить всё изученное в общую картину и заняться обучением этих самых квантовых нейронных сетей.\n",
    "\n",
    "## Введение\n",
    "\n",
    "Как уже было упомянуто в лекции по **VQC**, на данный момент квантовые вычислители ещё недостаточно развиты для того, чтобы в одиночку решать большие проблемы, имеющие практическое значение для индустрии  -- это в особенной степени актуально для нейронных сетей, которые и в классическом сценарии требуют значительных вычислительных ресурсов. Именно поэтому на данный момент наиболее популярна категория гибридных вариационных алгоритмов, которые обучают квантовую параметрическую схему (**QNN**) при помощи классической оптимизации, например, **VQ Eigensolvers** и **Quantum Approximate Optimization Algorithms**. В общем и целом идея гибридных алгоритмов заключается в оптимизации над некоторым классом параметрических вычислений для минимизации энергии волновой функции (**VQE**/**QAOA**), экстракции нелокальной информации (**QNN Classifiers**) или генерации квантового распределения данных (**Generative Models**).\n",
    "\n",
    "\n",
    "## Hybrid Quantum-Classical Networks\n",
    "В идеале этот подход подразумевал бы, что при помощи классического оптимизатора мы обучаем некоторую параметрическую схему на квантовом вычислителе, однако в текущих реалиях _NISQ_ этот подход является невозможным, поэтому большая часть параметрической схемы остаётся на классических вычислителях. В данном блоке мы поговорим о подходе, связанном с **QNN Classifiers**, которые следуют вышеупомянутому принципу и обучаются градиентным спуском практически так же, как и обычные классические сети, позволяя градиенту протекать между квантовой и классической частью сети.\n",
    "\n",
    "\n",
    "```{figure} /_static/qnnblock/qnntfq.png\n",
    ":name: qnn\n",
    ":height: 400px\n",
    "\n",
    "Схема обучения гибридной нейронной сети\n",
    "```\n",
    "\n",
    "На изображении гибридной сети процедура практически идентична классическому обучению сетей, в котором добавляется процесс кодирования классических данных в квантовые оператор, и процесс измерения квантового состояния для того, чтобы передать уже классическую информацию для дальнейших вычислений на классическом устройстве, как это было описано в лекции по **VQC**.\n",
    "\n",
    "## Ansatz\n",
    "\n",
    "Зачастую в литературе по **VQC**, особенно когда речь идёт о нейронных сетях, упоминается такая вещь как __ansatz__  -- по своей сути это заранее подготовленные участки параметрической схемы, которые могут быть использованы как составные блоки сети. Если проводить параллели с классическим машинным обучением, то в рамках библиотеки PennyLane эти схемы называются __templates__ и могут представлять собой, например, свёрточный слой или эмбеддинг, но и более общие элементы квантовой схемы вроде подготовки состояний или перестановок между кубитами.\n",
    "\n",
    "\n",
    "```{figure} /_static/qnnblock/cnnansatz.png\n",
    ":name: ansatz\n",
    ":height: 400px\n",
    "\n",
    "Ansatz, соответствующий свёрточному слою нейронной сети в PennyLane\n",
    "```\n",
    "\n",
    "## Функция потерь\n",
    "\n",
    "Функция потерь работает таким же образом, как и в полностью классических сетях, так как оптимизация происходит на классическом железе  -- единственное, что отличается, -- это объединение квантовых и классических градиентов. Градиент по нашей квантовой схеме получается при помощи замера состояния, которое может варьироваться из-за вероятностой природы кубита, поэтому несколько замеров позволяют аппроксимировать ожидаемый градиент при помощи методов вроде finite differences или parameter shift, после чего остаётся только совместить его с классическим.\n",
    "\n",
    "```{figure} /_static/qnnblock/qnngrads.png\n",
    ":name: grads\n",
    ":height: 400px\n",
    "\n",
    "Распространение градиентов от функции потерь в гибридной схеме.\n",
    "```\n",
    "\n",
    "## Network Itself\n",
    "\n",
    "В конечном итоге мы имеем следующую последовательность действий для того, чтобы собрать гибридную нейронную сеть:\n",
    "\n",
    " -- Трансформировать данные из классических в квантовые операторы;\n",
    " -- Отправить эти данные для вычисления на квантовой схеме;\n",
    " -- Просэмплировать и замерить результат квантовой схемы;\n",
    " -- Отправить результаты для вычисления на классической схеме;\n",
    " -- Оценить ошибку, рассчитать градиенты и обновить параметры.\n",
    "\n",
    "Именно эти 5 шагов мы увидим в следующем примере обучения гибридной нейронной сети.\n",
    "\n",
    "## Worked Example\n",
    "\n",
    "\n",
    "\n",
    "## Что мы узнали из лекции\n",
    "\n",
    " -- В ближайшие годы полностью квантовые нейронные сети не смогут решать задачи целиком, поэтому будут использоваться в качестве составляющей гибридного квантово-классического решения.\n",
    " -- Обучение подобных сетей практически идентично обучению классических сетей за исключением нескольких трюков, необходимых для работы с параметрами квантовых схем."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "source_map": [
   11
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}