---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

(hogradients)=

# Градиенты высших порядков

## План лекции

В этой лекции мы посмотрим на ту математику, которая лежит "под капотом" у _parameter-shift rule_. Также мы увидим, как можно оптимизировать этот метод, а еще узнаем как можно посчитать производную второго порядка. Дополнительно мы коснемся темы различных оптимизаторов применительно вариационных квантовых схем.

Для более детального погружения в вопрос можно сразу рекомендовать статью {cite}`hogradients`.

## Важность гейтов вращений

Если задуматься, то одним из основных (если не единственных) способов сделать параметризованную квантовую схему является использование гейтов вращений, таких как $\hat{RX}, \hat{RY}, \hat{RZ$. Более формально это можно выразить так, что нас больше всего интересуют операторы вида:

$$
U(\theta) = e^{-\frac{i}{2}H\theta}
$$

где $H$ -- матрица такая, что $H^2 = \mathbf{1}$. Другой возможный вариант записи -- представить матрицу $H$ как линейную комбинацию операторов Паули $\sigma^x, \sigma^y, \sigma^z$. Для простоты далее мы рассмотрим лишь случай, когда у нас всего один гейт, но на самом деле с точки зрения производной это не столь важно, так как каждый гейт чаще всего параметризуется своим классическим параметром, а нам нужна именно производная. А значит, по правилам дифференцирования нас будут мало волновать гейты, параметризованные другими параметрами, ведь их вклад в производную будет нулевым.

## Производная от измерения

Давайте вспомним, как выглядит квантово-классическая схема обучения с **VQC**.

```{figure} /_static/vqcblock/vqc/diagram.png
:name: quantclassical
:height: 400px

Квантово-классическая схема
```

Видно, что мы хотим считать производную не от самого параметризованного гейта $U(\theta)$, а от наблюдаемой. Для тех, кто забыл, что такое _наблюдаемая_, рекомендуем вернуться к лекции про кубит. Если кратко, то это тот оператор, который мы "измеряем" на нашем квантовом компьютере. Математически производная, которая нам интересна может быть записана так:

$$
G = \frac{\partial \bra{U(\theta)\Psi}\hat{M}\ket{U(\theta)\Psi}}{\partial \theta}
$$

То есть нам важно посчитать производную от результата измерения, так как именно результат измерения у нас будет определять "предсказание" нашей квантовой нейронной сети.

## Обобщенный parameter-shift

Так как выражение для нашей наблюдаемой может быть представлено {cite}`hogradients` как сумма вида:

$$
\bra{U(\theta)\Psi}\hat{M}\ket{U(\theta)\Psi} = \hat{A} + \hat{B}\cos{\theta} + \hat{C}\sin{\theta}
$$

где $\hat{A}, \hat{B}, \hat{C}$ -- операторы, не зависящие от параметра
